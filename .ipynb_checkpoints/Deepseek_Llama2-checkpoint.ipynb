{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e266de82-279c-45a9-a42e-fcfe15d16629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ✅ Path to your multilingual FAQ file\n",
    "FAQ_FILE = \"faqs.txt\"\n",
    "\n",
    "# Initialize SentenceTransformer-based embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Function to extract Q&A pairs from the text (handles Q1:, A1:, etc.)\n",
    "def extract_qa_pairs_from_text(text: str):\n",
    "    qa_pairs = []\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    current_q = \"\"\n",
    "    current_a = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Match questions like Q1:, Q2:, A1:, A2: (case insensitive)\n",
    "        if line.lower().startswith(\"q\") and (\":\" in line):\n",
    "            if current_q and current_a:\n",
    "                qa_pairs.append(f\"{current_q}\\n{current_a}\")\n",
    "            current_q = line\n",
    "            current_a = \"\"\n",
    "        elif line.lower().startswith(\"a\") and (\":\" in line):\n",
    "            current_a = line\n",
    "        else:\n",
    "            # Continue appending to current question or answer\n",
    "            if current_a:\n",
    "                current_a += \" \" + line\n",
    "            elif current_q:\n",
    "                current_q += \" \" + line\n",
    "\n",
    "    if current_q and current_a:\n",
    "        qa_pairs.append(f\"{current_q}\\n{current_a}\")\n",
    "\n",
    "    # Debug: Print the extracted Q&A pairs\n",
    "    print(f\"Extracted {len(qa_pairs)} Q&A pairs.\")\n",
    "    for i, qa in enumerate(qa_pairs[:5]):  # Print first 5 Q&A pairs\n",
    "        print(f\"Q&A {i+1}: {qa[:200]}...\")  # Show a preview of the Q&A\n",
    "\n",
    "    return [Document(page_content=qa, metadata={\"source\": \"faqs.txt\"}) for qa in qa_pairs]\n",
    "\n",
    "# Function to process the FAQ file and store the data in FAISS\n",
    "def process_faq_file():\n",
    "    if not os.path.exists(FAQ_FILE):\n",
    "        return f\"❌ File '{FAQ_FILE}' not found.\"\n",
    "\n",
    "    # Read and print raw content of the FAQ file\n",
    "    with open(FAQ_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Debug: Print raw content for inspection\n",
    "    print(f\"Raw content from {FAQ_FILE}:\")\n",
    "    print(text[:500])  # Print first 500 characters of the file for inspection\n",
    "\n",
    "    qa_docs = extract_qa_pairs_from_text(text)\n",
    "\n",
    "    # Debug: Check if qa_docs has content\n",
    "    if not qa_docs:\n",
    "        return \"❌ No Q&A pairs extracted. Please check the format of 'faqs.txt'.\"\n",
    "\n",
    "    # Optional chunking\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50)\n",
    "    chunks = splitter.split_documents(qa_docs)\n",
    "\n",
    "    # Ensure there is content to embed\n",
    "    if not chunks:\n",
    "        return \"❌ No content to process after splitting.\"\n",
    "\n",
    "    # Extract text for embedding\n",
    "    texts = [chunk.page_content for chunk in chunks]\n",
    "\n",
    "    # Ensure text is not empty\n",
    "    if not all(texts):\n",
    "        return \"❌ Some text chunks are empty.\"\n",
    "\n",
    "    # Create FAISS index using the embeddings\n",
    "    try:\n",
    "        embeddings = embedding_model.embed_documents(texts)\n",
    "        if not embeddings or len(embeddings) != len(texts):\n",
    "            return \"❌ Error: Mismatch in number of embeddings and texts.\"\n",
    "\n",
    "        vector_store = FAISS.from_documents(chunks, embedding_model)\n",
    "        vector_store.save_local(\"faiss_faq_db\")\n",
    "\n",
    "        return f\"✅ {len(texts)} multilingual Q&A chunks stored in FAISS!\"\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error during FAISS processing: {str(e)}\"\n",
    "\n",
    "# Run the script\n",
    "if not os.path.exists(\"faiss_faq_db\"):\n",
    "    print(process_faq_file())\n",
    "else:\n",
    "    print(\"✅ FAISS FAQ DB already exists.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
